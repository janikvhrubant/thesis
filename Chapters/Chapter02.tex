%!TEX root = ../main.tex
\chapter{Discrepancy Theory and Low-Discrepancy Sequences}
\label{chapter2}

% ------------------------------------------------------------------------------
\section{Measuring Uniformity: Discrepancy}
% ------------------------------------------------------------------------------

One of the cornerstones of \ac{qmc} theory is the concept of \emph{discrepancy},
which quantifies how uniformly a finite point set samples the $s$-dimensional
unit cube $[0,1]^s$. While uniform distribution modulo one describes the
asymptotic behavior of infinite sequences, discrepancy provides a finite-sample
measure of deviation from perfect uniformity. Low-discrepancy sequences are the
foundation of \ac{qmc} methods because they minimize this deviation and thus
yield more accurate numerical integration.

This section introduces formal definitions, geometric intuition and empirical
insights into discrepancy measures. It lays the theoretical groundwork for
understanding how the structure of point sets affects \ac{qmc} integration
performance.

% ------------------------------------------------------------------------------
\subsection{Definition of Discrepancy and Star Discrepancy}
% ------------------------------------------------------------------------------

First, we define the more general \emph{extreme discrepancy}:

\begin{definition}[Extreme Discrepancy] \ \\
Let $\mathcal{P}\subset [0,1)^s$, with $|\mathcal{P}| = N$, being a finite point
set. Then the extreme discrepancy $D_N(\mathcal{P})$ is defined as
\begin{equation*}
    D_N(\mathcal{P}) = \sup\limits_{\substack{\boldsymbol{a,b} \in [0,1]^s \\ \boldsymbol{a} \leq \boldsymbol{b}}} \bigg| \frac{A([\boldsymbol{a},\boldsymbol{b}) , \mathcal{P}, N)}{N} - \lambda_s([\boldsymbol{a},\boldsymbol{b})] \bigg|.
\end{equation*}
Hereby $A([\boldsymbol{a},\boldsymbol{b}), \mathcal{P}, N)$ denotes the number
of points in $\mathcal{P}$ that fall into the box
$[\boldsymbol{a},\boldsymbol{b})$, and
$\lambda_s([\boldsymbol{a},\boldsymbol{b})]$ is the Lebesgue measure of that
box, given by $\prod_{i=1}^{s} (b_i - a_i)$.
\end{definition}

In practice, a common and slightly more tractable variant is the \emph{star
discrepancy}, which restricts the test boxes to be anchored at the origin.

\begin{definition}[Star Discrepancy] \ \\
Let $\mathcal{P}\subset [0,1)^s$, with $|\mathcal{P}| = N$, being a finite point
set. Then the star discrepancy $D_N^*$ is defined as
\begin{equation*}
    D_N^*(\mathcal{P}) = \sup\limits_{\boldsymbol{t} \in [0,1]^s} \bigg| \frac{A([\boldsymbol{0},\boldsymbol{t}), \mathcal{P}, N)}{N} - \lambda_s([\boldsymbol{0},\boldsymbol{t})] \bigg|.
\end{equation*}
\end{definition}

This form is used in the Koksma--Hlawka inequality and serves as a central
measure in \ac{qmc} analysis. Note that both discrepancy definitions are
deterministic and depend solely on the point configuration.

\begin{remark}
A low star discrepancy implies that the empirical distribution of the points
approximates the uniform distribution well over all axis-aligned subrectangles
anchored at the origin.
\end{remark}

% ------------------------------------------------------------------------------
\subsection{Geometric Interpretation and Examples}
% ------------------------------------------------------------------------------

To build geometric intuition, consider the 1-dimensional case. Given $N$ sample
points $x_0, \dots, x_{N-1} \in [0,1)$, we can visualize discrepancy as the
maximum vertical deviation between the empirical distribution function
\begin{equation*}
F_N(t) := \frac{1}{N} \sum_{n=0}^{N-1} \chi_{[0,t)}(x_n)
\end{equation*}
and the uniform cumulative distribution function $F(t) = t$. The discrepancy
corresponds to the largest gap between $F_N(t)$ and $F(t)$.

In higher dimensions, the idea generalizes: the star discrepancy measures the
maximal difference in the number of points falling into an axis-aligned box
$[\boldsymbol{0}, \boldsymbol{t})$ versus the volume of that box. Intuitively,
it quantifies whether the point set "overpopulates" or "underpopulates" certain
regions.

\begin{figure}[H]
\centering
\includegraphics[scale=.67]{Figures/discrepancy1d.png}
\caption{Visualization of 1D discrepancy: the maximum vertical distance between the empirical CDF $F_N(t)$ and the uniform CDF $F(t) = t$.}
\label{fig:discrepancy-1d}
\end{figure}

\begin{example}
Let $x_n = \frac{n}{N}$ for $n = 0, \dots, N-1$. Then $F_N(t)$ is a
piecewise constant staircase function, and the discrepancy can be shown to be
$\mathcal{O}(1/N)$. This is an optimal rate in 1D.
\end{example}

\begin{remark}
Discrepancy provides a worst-case error metric over all subintervals. Thus, even
a point set that appears visually well-distributed may have large discrepancy
due to subtle gaps or clustering in certain regions.
\end{remark}

% ------------------------------------------------------------------------------
\subsection{Empirical Observation of Discrepancy in QMC}
% ------------------------------------------------------------------------------

Discrepancy is not just a theoretical construct -- its practical relevance
becomes evident when comparing the behavior of \ac{qmc} sequences with \ac{mc}
samples. In particular, structured point sets like Halton and Sobol' sequences
achieve much lower discrepancy than random samples of the same size.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{Figures/qmc_discrepancy_comparison.png}
\caption{Comparison of discrepancy growth for Sobol', Halton and random
(\ac{mc}) point sets in 2D. Low-discrepancy sequences exhibit significantly
slower discrepancy growth.}
\label{fig:qmc-discrepancy-comparison}
\end{figure}

\begin{remark}
The expected star discrepancy of i.i.d. Monte Carlo samples decreases at the
rate $\mathcal{O}(N^{-1/2})$, whereas for low-discrepancy sequences, provable
upper bounds of order $\mathcal{O}((\log N)^s / N)$ exist.
\cite[Section~2.2]{leobacher2014introduction}
\end{remark}

The next section will introduce specific constructions of low-discrepancy
sequences and analyze their dimensional performance and implementation details.


% ------------------------------------------------------------------------------
\section{Construction of Low-Discrepancy Sequences}
% ------------------------------------------------------------------------------

Before defining specific low-discrepancy sequences, we first introduce the term of low-discrepancy sequences, which are designed to fill the unit cube $[0,1)^s$
as uniformly as possible.

\begin{definition}[Low-Discrepancy Sequence] \ \\
A sequence $\mathcal{S} = (x_n)_{n\in \mathbb{N}}$ in $[0,1)^s$ is called a low-discrepancy sequence if its star discrepancy satisfies
\begin{equation*}
    D_N^*(\mathcal{S}) = \mathcal{O}\left( \frac{(\log N)^s}{N} \right)
\end{equation*}
for all $N \in \mathbb{N}$. Such sequences are also referred to as
\emph{quasi-Monte Carlo sequences} or \ac{qmc} sequences.
\end{definition}

Low discrepancy sequences are constructed to minimize the star
discrepancy, which is crucial for the convergence of \ac{qmc} methods according to the Koksma-Hlawka inequality introduced in Chapter~\ref{chapter3}.

% ------------------------------------------------------------------------------
\subsection{The Halton Sequence}
\label{subsec:halton-sequence}
% ------------------------------------------------------------------------------

The Halton sequence is one of the earliest and most widely used constructions of
low-discrepancy sequences in arbitrary dimensions. 

For the construction of the Halton sequence, we utilize the radical-inverse
functin $\phi_b(n)$. The radical-inverse function $\phi_b(n)$ maps an integer
$n$ to a real number in $[0,1)$ by reflecting its base-$b$ representation about
the decimal point:
\begin{equation*}
    \phi_b(n) = \sum_{k=0}^\infty d_k b^{-k-1}, \quad \text{where } n = \sum_
    {k=0}^\infty d_k b^k.
\end{equation*}

\begin{definition}[Van der Corput Sequence] \ \\
\label{def:van-der-corput-sequence}
The one-dimensional van der Corput sequence in base $b$ is defined as
\begin{equation*}
    \mathcal{S}_b = \left( \phi_b(n) \right)_{n\in \mathbb{N}}.
\end{equation*}
\end{definition}

The Halton sequence generalizes the one-dimensional van der Corput sequence to
multiple dimensions by using mutually prime bases.

\begin{definition}[Halton Sequence] \ \\
Let $b_1, \dots, b_s$ be pairwise coprime integers greater than $1$, typically
chosen as the first $s$ prime numbers. The $n$-th point $\boldsymbol{x}_n \in
[0,1)^s$ of the $s$-dimensional Halton sequence is defined componentwise by
\begin{equation*}
    \boldsymbol{x}_n = \left( \phi_{b_1}(n), \dots, \phi_{b_s}(n) \right),
\end{equation*}
where $\phi_b(n)$ denotes the van der Corput radical-inverse function in base
$b$. The Halton sequence is then given by $\mathcal{S}_{b_1, \dots, b_s} = (x_n)_{n\in \mathbb{N}}$.
\end{definition}

\begin{example}[First Elements of the Halton Sequence in 2D] \ \\
Consider the two-dimensional Halton sequence based on the first two prime bases $b_1 = 2$ and $b_2 = 3$. The first three elements are obtained by computing the radical-inverse values $\phi_{b_1}(n)$ and $\phi_{b_2}(n)$ for $n = 1, 2, 3$:

\begin{itemize}
    \item $n = 1$: $\boldsymbol{x}_1 = \left( \phi_2(1), \phi_3(1) \right) = \left( \tfrac{1}{2}, \tfrac{1}{3} \right)$
    \item $n = 2$: $\boldsymbol{x}_2 = \left( \phi_2(2), \phi_3(2) \right) = \left( \tfrac{1}{4}, \tfrac{2}{3} \right)$
    \item $n = 3$: $\boldsymbol{x}_3 = \left( \phi_2(3), \phi_3(3) \right) = \left( \tfrac{3}{4}, \tfrac{1}{9} \right)$
\end{itemize}

This illustrates how the Halton sequence fills the unit square in a low-discrepancy manner even for small $n$.
\end{example}








Intuitively, this construction ensures that each component of the sequence
explores the unit interval in a structured, non-redundant way. By combining
several one-dimensional van der Corput sequences in different coprime bases, the
resulting multi-dimensional point set avoids regular grid-like patterns and
achieves asymptotic uniformity.

As stated in \cite{pillichshammer2010zahlentheoretische}, the Halton sequence
has star discrepancy of order
\begin{equation*}
    D_N^*(\{\boldsymbol{x}_0, \dots, \boldsymbol{x}_{N-1}\}) = \mathcal{O}\left( \frac{(\log N)^s}{N} \right),
\end{equation*}
making it a prototypical example of a low-discrepancy sequence. However, for
larger dimensions, correlation effects between the different base components can
lead to degraded uniformity and higher discrepancy. Variants such as scrambling
or leaping are commonly employed to mitigate this issue.

\begin{remark}
The Halton sequence is extensible in $N$ and $s$, making it suitable for
applications that require growing or adaptive point sets. However, its
performance in high dimensions is often inferior to more modern constructions
like the Sobol' sequence.
\end{remark}


% ------------------------------------------------------------------------------
  \subsection{The Sobol' Sequence}
% ------------------------------------------------------------------------------

Sobol' sequences are another class of low-discrepancy sequences that are widely
used in \ac{qmc} methods, particularly for high-dimensional problems.
Constructed to fill the $s$-dimensional unit cube $[0,1)^s$ as uniformly as
possible, Sobol' sequences are based on a recursive structure that allows for
efficient generation and high-dimensional performance.

\begin{definition}[Sobol' Sequence Construction]
Let $p_1, \dots, p_s \in \mathbb{F}_2[x]$ be primitive polynomials ordered by non-decreasing degree. Each polynomial $p_j$ for dimension $j$ is of the form
\begin{equation*}
    p_j(x) = x^{e_j} + a_{1,j}x^{e_j - 1} + \dots + a_{e_j - 1,j}x + 1,
\end{equation*}
where $e_j \in \mathbb{N}$ and the coefficients $a_{k,j} \in \{0,1\}$.

Choose initial values $m_{1,j}, \dots, m_{e_j,j}$ such that each $m_{k,j}$ is an odd integer and $1 \leq m_{k,j} < 2^k$ for $1 \leq k \leq e_j$. For $k > e_j$, the values $m_{k,j}$ are computed recursively as:
\begin{equation*}
    m_{k,j} = a_{1,j} \cdot 2 m_{k-1,j} \oplus a_{2,j} \cdot 2^2 m_{k-2,j} \oplus \dots \oplus a_{e_j-1,j} \cdot 2^{e_j-1} m_{k-e_j+1,j} \oplus 2^{e_j} m_{k-e_j,j} \oplus m_{k-e_j,j},
\end{equation*}
where $\oplus$ denotes bitwise exclusive-or (XOR).

The corresponding direction numbers are defined by
\begin{equation*}
    v_{k,j} = \frac{m_{k,j}}{2^k}.
\end{equation*}

Let $n \in \mathbb{N}_0$ with binary expansion
\begin{equation*}
    n = n_0 + 2n_1 + \dots + 2^{r-1}n_{r-1}, \quad n_i \in \{0,1\}.
\end{equation*}
Then the $j$-th coordinate of the $n$-th Sobol' point is given by
\begin{equation*}
    x_{n,j} = n_0 v_{1,j} \oplus n_1 v_{2,j} \oplus \dots \oplus n_{r-1} v_{r,j}.
\end{equation*}
The $s$-dimensional Sobol' point is
\begin{equation*}
    \boldsymbol{x}_n = (x_{n,1}, \dots, x_{n,s}).
\end{equation*}
\end{definition}

\begin{remark}
In dimension $j = 1$, the polynomial is typically chosen as $p_1(x) = x$, which
leads to a construction equivalent to the van der Corput sequence in base $2$
from Definition~\ref{def:van-der-corput-sequence}.
\end{remark}

The bitwise structure of the Sobol' sequence makes it particularly efficient to
generate and it enables streaming or online sampling in high dimensions.

% ------------------------------------------------------------------------------
\subsection{Dimensional Performance and Sequence Comparison}
\label{subsec:dimensional-performance}
% ------------------------------------------------------------------------------

The practical performance of low-discrepancy sequences is strongly influenced by
the dimension $s$ of the integration domain. Although both Halton and Sobol'
sequences achieve the asymptotic star discrepancy bound of order
$\mathcal{O}((\log N)^s / N)$ (as will be shown in Chapter~\ref{chapter3}),
their behavior in higher dimensions differs significantly in practice.

\paragraph{Halton Sequence.}
While the Halton sequence performs well in low-dimensional settings, its
structure leads to correlation artifacts in higher dimensions due to the use of
increasing prime bases. These artifacts manifest as clustering or gaps in
certain coordinate directions, which can degrade uniformity. As a result, the
empirical discrepancy of the Halton sequence often grows faster than the
theoretical bound suggests in moderate to high dimensions.

\paragraph{Sobol' Sequence.}
In contrast, the Sobol' sequence is explicitly constructed for high-dimensional
performance. The use of carefully selected primitive polynomials and direction
numbers minimizes inter-dimensional correlations. Furthermore, the bitwise
construction allows for better numerical stability and efficient implementation.
Sobol' sequences generally exhibit lower discrepancy than Halton sequences in
dimensions $s > 10$, making them a standard choice in modern \ac{qmc}
applications.

The below Figure~\ref{fig:dimensional-comparison} illustrates the difference in
a two-dimensional setting between the two low discrepancy sequences. The Sobol'
sequence fills the unit square more uniformly, while the Halton sequence shows
visible clustering.

\begin{figure}[H]
\label{fig:dimensional-comparison}
\centering
\includegraphics[width=0.8\textwidth]{Figures/sobol-vs-halton.png}
\caption{Comparison of Halton and Sobol' sequences in $s=2$ dimensions for
$N=1024$ points. The Sobol' sequence fills the unit square more uniformly,
demonstrating lower star discrepancy than the Halton sequence.}
\label{fig:dimensional-comparison}
\end{figure}

\begin{remark}
In high-dimensional problems, particularly those arising in computational
finance or scientific simulations, Sobol' sequences with proper scrambling
consistently outperform Halton sequences in terms of integration accuracy and
numerical stability.
\end{remark}

\paragraph{Summary Table.}
The following table summarizes the key characteristics of both sequences:

\begin{table}[H]
\centering
\begin{tabular}{lcc}
\toprule
\textbf{Property} & \textbf{Halton} & \textbf{Sobol'} \\
\midrule
Extensible in $N$          & Yes  & Yes \\
Extensible in $s$          & Yes  & Yes \\
Asymptotic Star Discrepancy & $\mathcal{O}\big(\frac{(\log N)^s}{N}\big)$ & $\mathcal{O}\big(\frac{(\log N)^s}{N}\big)$ \\
High-Dimensional Performance & Limited & Excellent \\
Implementation Cost         & Low & Moderate \\
\bottomrule
\end{tabular}
\caption{Qualitative comparison of Halton and Sobol' sequences.}
\label{tab:halton-sobol-comparison}
\end{table}
